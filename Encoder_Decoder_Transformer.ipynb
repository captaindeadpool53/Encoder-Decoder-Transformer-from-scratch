{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/captaindeadpool53/Encoder-Decoder-Transformer-from-scratch/blob/main/Encoder_Decoder_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OfM3wFis8xIx",
        "outputId": "8e4294c1-5783-4759-9f03-8e127ce6a19f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "MJWs0N8Bx2zT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64267bfd-032d-48ad-f1d0-d3f32d88f919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "source": [
        "!pip install --upgrade datasets fsspec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "e5ad5b9fbb2f48d2abc9d21877ff8d92",
            "cc5ac288117c4e4fad8fb9c846661436",
            "2d853efcea8e4afc9c18cef2cd2978f0",
            "9f8327450a5e4b3481a72c3e773e8999",
            "1fe3fee2f54948b0bbfde054df3f6fbb",
            "8731c4ef1cb746b0b3e802d7722f37d9",
            "b2836a1cf81643eabf4f6268f24043c3",
            "e7637abcd3cf44a18085e0567944141c",
            "df08003746a5406395cd034169357b51",
            "43a382ebe5d34d879a2d31961749ae6c",
            "84709165cbed491fb1228d300669af62",
            "2a6adab714974c2d950f4830ca2a9123",
            "1983de608b444ef99aa5b6b35118d00d",
            "2de4b01d7eea49ffa279883a363c02d3",
            "18eaf5679c1e4f0aacfd0f38691f9ad3",
            "be2c1a515dd64c0389d3652adeb9b3d1",
            "e94f712d868248629be42c2de6ab9990",
            "8cc849d50f24404a97696ae97a82fd9a",
            "4adea025cac24b898c403c47ca1570a0",
            "afff9848c6d8470aaf04300e0b9f7502",
            "f19217a9eb68456c8a125653fcc1d215",
            "556b82be2db0449e85f914776ea654cb",
            "34d1a5c33e3f4f9493ae19f42556aa15",
            "c61ce2ae7f8346d89dd3df39b80263a9",
            "37996bff30514004b27126ae58907746",
            "5a3366fa82a74be7b2066abe876c8b94",
            "4d9bb48627f844b4a25f3e907a75a8a8",
            "114577d5111b4bac942489f826e049d9",
            "e6c06076909946cbae011c451c7ac19b",
            "39daa21a5a05455a89d76432a7775c3a",
            "887de2b9246b42dfa8a1f7765b28df7a",
            "7694f14119d54a7898bae8ac5ef2b00d",
            "309a302dcc9d448487547eb04d21b056"
          ]
        },
        "id": "4hH5Lequ5WKA",
        "collapsed": true,
        "outputId": "6c088509-38fe-4210-e78f-c6ec3dedc150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "books = load_dataset(\"opus_books\", \"en-fr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P3G_UaSyEWW",
        "outputId": "4b6ba8e4-6da4-4b95-c8f5-51c2c2bb53b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 101668\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 25417\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Dataset structure\n",
        "books = books[\"train\"].train_test_split(test_size=0.2)\n",
        "books"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxQeE1YBySr5",
        "outputId": "0407c65c-3430-4ba6-a35b-1411c0ab0c35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '36635',\n",
              " 'translation': {'en': 'All is over between us.',\n",
              "  'fr': 'Tout est donc fini entre nous.'}}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Example structure\n",
        "books[\"train\"][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UlKc1A9x56GC",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "dd68a62f94014ba7a667b7a38f7ff582",
            "f4753b70a20a4d52a714752d2816d9a3",
            "a273fa1766b84c9b89d2460abaffb0d4",
            "d9719dfdbce3499b95b08d4b81184f1b",
            "20c6d2ec12674a1a8c3c5a5d8376a978",
            "59363d9898524ddea288ef15fecd62c5",
            "e09bb78a7edb4416901029f5d72accce",
            "f9ea3beac270402884c786a87ec7a2b5",
            "806e11b57b2d4e649a815df6dcda96f8",
            "0a10be23483b4c9f822cea28d5ef2f43",
            "732783981bda40b2852ad90b4ed5fa50",
            "e4ced3dcec404879b80734f89a6b07a5",
            "8a2f255e0f414bcb9c8b9128280ebfc5",
            "d3c3b5e97d4f4dab8d1e3d96f2ceb0ac",
            "90b68f3a20a543e480658245d38627e7",
            "d500024e2a7f4ceaa09c0ed085b736d3",
            "80dd3160095e4ceba0440122d0cd9be6",
            "196b13d7d6c943e0961d55acea44391d",
            "c713b0784e02481c819496ef0e4c13c4",
            "b93b5f88ebbd4798873e4dad3932baab",
            "bd820766ee6e409dab8219a3642aee86",
            "6e73031d54ed46458733dc5dfbdb85fc",
            "3decad66dfbc41cc95860c9c7bcbbb4f",
            "e60e654c574346b5857c0836881645b0",
            "535f5b1763b34e06b7c1972511b581ad",
            "cd5e4b16259f4ca09f7f34218e24aa99",
            "4167231d64484344a84628ba34b544dd",
            "6b88f291c340402299d2efaa2ab0bde3",
            "22c3e2fb117e49589127b85f8e438875",
            "e2867a5a129f4ce69557793afe03c3eb",
            "6e72f2fa9d52450eab4f81da9c1edc5c",
            "c46b8a82776e41219f0bf3ee96257c62",
            "6a45be3f61cb40eb98525dc5e5e4f511",
            "8327fd1dabe647c8b63800edc779529b",
            "586d15993bf24a319d41cb112e176a30",
            "c099f00fa9144a77867f92fb6d8f1dfd",
            "b691b82dcb4e4c31afa43fcffdecbd22",
            "52e2fb92b315489bb0705e62f2db836a",
            "47aed798ae004c67bb76a6dbdf04d830",
            "a8405d33da70427a9e0fbe9e3dfc3f60",
            "86341885fb2449dcad05f9f5881f5231",
            "e7a44f4cd9584b6290262017cb44cdce",
            "bc112411892742ad93ccb37f1b92333d",
            "12468c1eb9ad401a9645f97e057c62f3",
            "4b4224a14bf04ed7bf8e4429d5e7bcd1",
            "65ebb698b5d045ebae7024752da62680",
            "94a9257047434512bdf4e7adf9494230",
            "55ab7733c98f44d98391b5d452ea7dd1",
            "94b4a5be2cd34d10832df48159525a06",
            "043e0a7eeb114597a93ad3b9a8864aaa",
            "444c533a588d437e8f1dbb4a8295bc14",
            "cdf34170381f4171a164db8501abe292",
            "075fb743e8164f629ec4d4e35e992766",
            "638c1cfedabc4e4e8540b96dbfe6dc36",
            "a41d67c2af254833af6e013e83baf5e0"
          ]
        },
        "outputId": "8f21be20-4b9d-4639-a0e3-abef9204dbbb"
      },
      "outputs": [
      ],
      "source": [
        "# BPE Tokenization used by GPT2 from HuggingFace\n",
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvZG27WjAprl",
        "outputId": "f134c679-31da-44f1-dc4f-201c32d37b7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50258"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.add_special_tokens({'pad_token': '<|pad|>'})\n",
        "tokenizer.pad_token = '<|pad|>'\n",
        "tokenizer.bos_token = '<|bos|>'\n",
        "len(tokenizer) #vocab length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wLXL4EmmBc5V",
        "outputId": "79aa20ea-3161-4f4f-c2d3-837c240f9aa9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|pad|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tokenizer.pad_token"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = [len(tokenizer(example['translation']['fr']).input_ids) for example in books[\"train\"]]"
      ],
      "metadata": {
        "id": "iVGTBka7EgOn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: generate a frequency distribution curve for lengths\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(lengths, bins=50, density=True, alpha=0.75)\n",
        "plt.xlabel('Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Frequency Distribution of Lengths')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "CoYqBAPaCjAZ",
        "outputId": "ef1e1dff-b785-44bc-e79e-c61a6918dc49"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAHHCAYAAACfqw0dAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVXZJREFUeJzt3XtYVNX+BvB3uAzDRUBBGVQEMkpNFMUkjNISAaWULFPzBgf1l2mipCWm4iXFNE1Li6xEO+rBTCMzI0bUOiVhIuSlNDWVEgc0k1FMbrN+f/iwjyPDbTs4jL6f55mnZu211157f0d53bNmUAghBIiIiIioQazMPQEiIiIiS8QQRURERCQDQxQRERGRDAxRRERERDIwRBERERHJwBBFREREJANDFBEREZEMDFFEREREMjBEEREREcnAEEVEFmPu3LlQKBR35Fh9+vRBnz59pOd79+6FQqHAZ599dkeOHx0dDR8fnztyLLmuXr2KsWPHQq1WQ6FQYMqUKeaeksnd6bqTZWGIIrrJunXroFAojD5mzJhh7undVW691iqVCq1bt0Z4eDjeeecdXLlyxSTHKSgowNy5c5GXl2eS8UypKc+tPhYtWoR169ZhwoQJ+Pe//41Ro0bV2NfHxwdPPfXUHZxdw2zatAkrVqww9zTIwtiYewJETdH8+fPh6+tr0Na5c2czzebuVnWty8vLodVqsXfvXkyZMgXLly/H9u3b0aVLF6nvrFmzGhxmCwoKMG/ePPj4+CAgIKDe+2VkZDToOHLUNrcPP/wQer2+0edwO3bv3o1HHnkEiYmJ5p7Kbdu0aROOHDlyV95No8bDEEVkRP/+/dGjR4969b1+/TqUSiWsrHhjV45br3VCQgJ2796Np556CgMHDsSvv/4Ke3t7AICNjQ1sbBr3r61r167BwcEBSqWyUY9TF1tbW7Mevz6KiorQqVMnc0+DyGz4tz5RA1Stj0hNTcWsWbPQpk0bODg4QKfTAQCys7MREREBFxcXODg4oHfv3vjhhx+qjfP999/j4YcfhkqlQvv27fHBBx9UW+9z5swZKBQKrFu3rtr+CoUCc+fONWg7d+4c/vWvf8HDwwN2dnZ46KGHsHbtWqPz//TTT7Fw4UK0bdsWKpUKffv2xcmTJ6sdJzs7GwMGDEDz5s3h6OiILl26YOXKlQCAlJQUKBQK5ObmVttv0aJFsLa2xrlz5+q8psY8+eSTmD17Ns6ePYsNGzZI7cbWRGk0GoSEhMDV1RVOTk548MEHMXPmTOl8H374YQBATEyM9NZh1TXt06cPOnfujJycHDz++ONwcHCQ9r11TVSVyspKzJw5E2q1Go6Ojhg4cCD++OMPgz4+Pj6Ijo6utu/NY9Y1N2NrokpKSvDKK6/Ay8sLdnZ2ePDBB/HWW29BCGHQT6FQYNKkSUhLS0Pnzp2l10N6errxC36LoqIixMbGwsPDAyqVCl27dsX69eul7VWvo9OnT+Orr76S5n7mzJl6jV+bDRs2IDAwEPb29mjRogWGDRtW7fpW1e2XX37BE088AQcHB7Rp0wZLliypNt7Zs2cxcOBAODo6olWrVpg6dSq++eYbKBQK7N27Vxrvq6++wtmzZ6VzufXa6/X6Ov/MnDhxAs8++yzUajVUKhXatm2LYcOGobi4+LavCzVNvBNFZERxcTEuXrxo0Obu7i79/4IFC6BUKjFt2jSUlpZCqVRi9+7d6N+/PwIDA5GYmAgrKyukpKTgySefxH//+1/07NkTAHD48GGEhYWhZcuWmDt3LioqKpCYmAgPDw/Z8y0sLMQjjzwi/fBs2bIlvv76a8TGxkKn01V7i2Lx4sWwsrLCtGnTUFxcjCVLlmDEiBHIzs6W+mg0Gjz11FPw9PREXFwc1Go1fv31V+zYsQNxcXF47rnnMHHiRGzcuBHdunUzGH/jxo3o06cP2rRpI/ucRo0ahZkzZyIjIwPjxo0z2ufo0aN46qmn0KVLF8yfPx92dnY4efKkFFw7duyI+fPnY86cORg/fjwee+wxAECvXr2kMf766y/0798fw4YNw8iRI+usw8KFC6FQKPDaa6+hqKgIK1asQGhoKPLy8qQ7ZvVRn7ndTAiBgQMHYs+ePYiNjUVAQAC++eYbTJ8+HefOncPbb79t0P/777/Htm3b8NJLL6FZs2Z455138OyzzyI/Px9ubm41zuuff/5Bnz59cPLkSUyaNAm+vr7YsmULoqOjcfnyZcTFxaFjx47497//jalTp6Jt27Z45ZVXAAAtW7as9/kbs3DhQsyePRvPP/88xo4diwsXLuDdd9/F448/jtzcXLi6ukp9//77b0RERGDw4MF4/vnn8dlnn+G1116Dv78/+vfvD+BG6HzyySdx/vx56TW8adMm7Nmzx+C4r7/+OoqLi/Hnn39K19HJycmgT11/ZsrKyhAeHo7S0lK8/PLLUKvVOHfuHHbs2IHLly/DxcXltq4NNVGCiCQpKSkCgNGHEELs2bNHABD33XefuHbtmrSfXq8Xfn5+Ijw8XOj1eqn92rVrwtfXV/Tr109qi4qKEiqVSpw9e1Zq++WXX4S1tbW4+Y/k6dOnBQCRkpJSbZ4ARGJiovQ8NjZWeHp6iosXLxr0GzZsmHBxcZHmWjX/jh07itLSUqnfypUrBQBx+PBhIYQQFRUVwtfXV3h7e4u///7bYMybz2/48OGidevWorKyUmo7ePBgjfO+WdW1/umnn2rs4+LiIrp16yY9T0xMNLhGb7/9tgAgLly4UOMYP/30U43z6d27twAgkpOTjW7r3bu39Lzq2rVp00bodDqp/dNPPxUAxMqVK6U2b29vMWbMmDrHrG1uY8aMEd7e3tLztLQ0AUC88cYbBv2ee+45oVAoxMmTJ6U2AEKpVBq0/fzzzwKAePfdd6sd62YrVqwQAMSGDRuktrKyMhEcHCycnJwMzt3b21tERkbWOl59+545c0ZYW1uLhQsXGrQfPnxY2NjYGLRX1e2TTz6R2kpLS4VarRbPPvus1LZs2TIBQKSlpUlt//zzj+jQoYMAIPbs2SO1R0ZGGlzvKvX9M5ObmysAiC1bttR9MeiuwbfziIxYvXo1NBqNweNmY8aMMbjrkJeXhxMnTuCFF17AX3/9hYsXL+LixYsoKSlB37598d1330Gv16OyshLffPMNoqKi0K5dO2n/jh07Ijw8XNZchRDYunUrnn76aQghpGNfvHgR4eHhKC4uxsGDBw32iYmJMVjzU3UX5PfffwcA5Obm4vTp05gyZYrBv/4BGLydNnr0aBQUFBj8y37jxo2wt7fHs88+K+t8bubk5FTrp/Sq5vbFF1/IXoRtZ2eHmJiYevcfPXo0mjVrJj1/7rnn4OnpiZ07d8o6fn3t3LkT1tbWmDx5skH7K6+8AiEEvv76a4P20NBQtG/fXnrepUsXODs7SzWu7ThqtRrDhw+X2mxtbTF58mRcvXoV3377rQnOprpt27ZBr9fj+eefN3gNq9Vq+Pn5Vbt75OTkhJEjR0rPlUolevbsaXB+6enpaNOmDQYOHCi1qVSqGu9s1qauPzNVd5q++eYbXLt2rcHjk2Xi23lERvTs2bPWheW3fnLvxIkTAG6Eq5oUFxejtLQU//zzD/z8/Kptf/DBB2X9IL5w4QIuX76MNWvWYM2aNUb7FBUVGTy/OcABQPPmzQHceIsEAE6dOgWg7k8k9uvXD56enti4cSP69u0LvV6P//znPxg0aJBB0JDr6tWraNWqVY3bhw4dio8++ghjx47FjBkz0LdvXwwePBjPPfdcvRf6t2nTpkGLyG+tnUKhwP3332+S9UC1OXv2LFq3bl3tunbs2FHafrNbawzcqHNVjWs7jp+fX7XrV9NxTOXEiRMQQhj9swFUX2jftm3bauvjmjdvjkOHDknPz549i/bt21frd//99zd4fnX9mfH19UV8fDyWL1+OjRs34rHHHsPAgQMxcuRIvpV3F2OIIpLh1rUvVXdBli5dWuPH6J2cnFBaWlrvY9T0pZKVlZVGjz1y5MgaQ9zNXxMAANbW1kb7iVsWKNfF2toaL7zwAj788EO89957+OGHH1BQUGBwh0CuP//8E8XFxbX+wLO3t8d3332HPXv24KuvvkJ6ejo2b96MJ598EhkZGTWe561jmFpttavPnEzBVDW+U/R6PRQKBb7++mujc791jdKdPr/6HG/ZsmWIjo7GF198gYyMDEyePBlJSUn48ccf0bZt20aZF5kXQxSRCVS9beLs7IzQ0NAa+7Vs2RL29vbSnaubHT9+3OB51b90L1++bNB+652Ali1bolmzZqisrKz12A1RdT5Hjhypc8zRo0dj2bJl+PLLL/H111+jZcuWst+avNm///1vAKhzLCsrK/Tt2xd9+/bF8uXLsWjRIrz++uvYs2cPQkNDTf4N57fWTgiBkydPGgTV5s2bV6sbcKN29913n/S8IXPz9vbGrl27cOXKFYO7UceOHZO2m4K3tzcOHToEvV5vcDfK1Me5Vfv27SGEgK+vLx544AGTjOnt7Y1ffvkFQgiDa23sk6imep34+/vD398fs2bNwr59+/Doo48iOTkZb7zxhknGp6aFa6KITCAwMBDt27fHW2+9hatXr1bbfuHCBQA3/jUbHh6OtLQ05OfnS9t//fVXfPPNNwb7ODs7w93dHd99951B+3vvvWfw3NraGs8++yy2bt2KI0eO1HjshujevTt8fX2xYsWKamHg1n/pd+nSBV26dMFHH32ErVu3YtiwYbf9XU67d+/GggUL4OvrixEjRtTY79KlS9Xaqu4EVt31c3R0BFA9jMr1ySefGKzT+uyzz3D+/HnpE2HAjUDw448/oqysTGrbsWNHtY/qN2RuAwYMQGVlJVatWmXQ/vbbb0OhUBgc/3YMGDAAWq0WmzdvltoqKirw7rvvwsnJCb179zbJcW41ePBgWFtbY968edVeY0II/PXXXw0eMzw8HOfOncP27dultuvXr+PDDz+s1tfR0fG2vopAp9OhoqLCoM3f3x9WVlYNugNNloV3oohMwMrKCh999BH69++Phx56CDExMWjTpg3OnTuHPXv2wNnZGV9++SUAYN68eUhPT8djjz2Gl156SfoB9dBDDxms5wCAsWPHYvHixRg7dix69OiB7777Dr/99lu14y9evBh79uxBUFAQxo0bh06dOuHSpUs4ePAgdu3aZTRs1HU+77//Pp5++mkEBAQgJiYGnp6eOHbsGI4ePVot8I0ePRrTpk0DgAa/lff111/j2LFjqKioQGFhIXbv3g2NRgNvb29s374dKpWqxn3nz5+P7777DpGRkfD29kZRURHee+89tG3bFiEhIQBuBBpXV1ckJyejWbNmcHR0RFBQULV1bfXVokULhISEICYmBoWFhVixYgXuv/9+g8XKY8eOxWeffYaIiAg8//zzOHXqFDZs2GCw0Luhc3v66afxxBNP4PXXX8eZM2fQtWtXZGRk4IsvvsCUKVOqjS3X+PHj8cEHHyA6Oho5OTnw8fHBZ599hh9++AErVqy4rbVuJ0+eNHpHplu3boiMjMQbb7yBhIQEnDlzBlFRUWjWrBlOnz6Nzz//HOPHj5deY/X1f//3f1i1ahWGDx+OuLg4af1e1Wvq5rtPgYGB2Lx5M+Lj4/Hwww/DyckJTz/9dL2PtXv3bkyaNAlDhgzBAw88gIqKCvz73/+W/pFDdylzfCSQqKmq62P3VR93ruljzLm5uWLw4MHCzc1N2NnZCW9vb/H888+LzMxMg37ffvutCAwMFEqlUtx3330iOTm52sf3hbjxFQmxsbHCxcVFNGvWTDz//POiqKio2lccCCFEYWGhmDhxovDy8hK2trZCrVaLvn37ijVr1tQ5/5q+TuH7778X/fr1E82aNROOjo6iS5cuRj8if/78eWFtbS0eeOABo9fFmFu/TkKpVAq1Wi369esnVq5cafBR+iq3XqPMzEwxaNAg0bp1a6FUKkXr1q3F8OHDxW+//Waw3xdffCE6deokbGxsDM6zd+/e4qGHHjI6v5q+4uA///mPSEhIEK1atRL29vYiMjLS4Osqqixbtky0adNG2NnZiUcffVQcOHCg2pi1ze3WrzgQQogrV66IqVOnitatWwtbW1vh5+cnli5davC1E0Lc+IqDiRMnVptTTV+9cKvCwkIRExMj3N3dhVKpFP7+/ka/hqGhX3Fwc71vfsTGxkr9tm7dKkJCQoSjo6NwdHQUHTp0EBMnThTHjx+X+tRUN2PX7PfffxeRkZHC3t5etGzZUrzyyiti69atAoD48ccfpX5Xr14VL7zwgnB1dRUApHHq+2fm999/F//6179E+/bthUqlEi1atBBPPPGE2LVrV72uD1kmhRBNdJUh0T1m7ty5Rt/KsAQXL16Ep6cn5syZg9mzZ5t7OkS1WrFiBaZOnYo///zztr4Qlohroojotq1btw6VlZUYNWqUuadCZOCff/4xeH79+nV88MEH8PPzY4Ci28Y1UUQk2+7du/HLL79g4cKFiIqKqvb7xojMbfDgwWjXrh0CAgJQXFyMDRs24NixY9i4caO5p0Z3AYYoIpJt/vz50se43333XXNPh6ia8PBwfPTRR9i4cSMqKyvRqVMnpKamYujQoeaeGt0FuCaKiIiISAauiSIiIiKSgSGKiIiISAauiWpEer0eBQUFaNasmcl/9QQRERE1DiEErly5gtatW9f6y8wZohpRQUEBvLy8zD0NIiIikuGPP/6o9ZdHM0Q1oqpfj/DHH3/A2dnZZOOWl5cjIyMDYWFhsLW1Ndm4ZHqsleVgrSwL62U5LLFWOp0OXl5edf6aI4aoRlT1Fp6zs7PJQ5SDgwOcnZ0t5gV5r2KtLAdrZVlYL8thybWqaykOF5YTERERycAQRURERCQDQxQRERGRDAxRRERERDIwRBERERHJwBBFREREJANDFBEREZEMDFFEREREMjBEEREREcnAEEVEREQkA0MUERERkQxmD1GrV6+Gj48PVCoVgoKCsH///lr7b9myBR06dIBKpYK/vz927txpsH3btm0ICwuDm5sbFAoF8vLyDLafOXMGCoXC6GPLli1SP2PbU1NTTXbeREREZNnMGqI2b96M+Ph4JCYm4uDBg+jatSvCw8NRVFRktP++ffswfPhwxMbGIjc3F1FRUYiKisKRI0ekPiUlJQgJCcGbb75pdAwvLy+cP3/e4DFv3jw4OTmhf//+Bn1TUlIM+kVFRZns3ImIiMiy2Zjz4MuXL8e4ceMQExMDAEhOTsZXX32FtWvXYsaMGdX6r1y5EhEREZg+fToAYMGCBdBoNFi1ahWSk5MBAKNGjQJw446TMdbW1lCr1QZtn3/+OZ5//nk4OTkZtLu6ulbrS0RERASY8U5UWVkZcnJyEBoa+r/JWFkhNDQUWVlZRvfJysoy6A8A4eHhNfavj5ycHOTl5SE2NrbatokTJ8Ld3R09e/bE2rVrIYSQfRwiIiK6u5jtTtTFixdRWVkJDw8Pg3YPDw8cO3bM6D5ardZof61WK3seH3/8MTp27IhevXoZtM+fPx9PPvkkHBwckJGRgZdeeglXr17F5MmTaxyrtLQUpaWl0nOdTgcAKC8vR3l5uew53qpqrLrGjFlX+/oyAEiJ7mmSOZFx9a0VmR9rZVlYL8thibWq71zN+naeuf3zzz/YtGkTZs+eXW3bzW3dunVDSUkJli5dWmuISkpKwrx586q1Z2RkwMHBwTSTvolGo6l1+5BWdY9x68J8ahx11YqaDtbKsrBelsOSanXt2rV69TNbiHJ3d4e1tTUKCwsN2gsLC2tch6RWqxvUvy6fffYZrl27htGjR9fZNygoCAsWLEBpaSns7OyM9klISEB8fLz0XKfTwcvLC2FhYXB2dpY1R2PKy8uh0WjQr18/2Nra1tiPd6LMr761IvNjrSwL62U5LLFWVe8k1cVsIUqpVCIwMBCZmZnSp970ej0yMzMxadIko/sEBwcjMzMTU6ZMkdo0Gg2Cg4NlzeHjjz/GwIED0bJlyzr75uXloXnz5jUGKACws7Mzut3W1rZRXjh1jVsh6l7yZikvaEvXWK8BMj3WyrKwXpbDkmpV33ma9e28+Ph4jBkzBj169EDPnj2xYsUKlJSUSJ/WGz16NNq0aYOkpCQAQFxcHHr37o1ly5YhMjISqampOHDgANasWSONeenSJeTn56OgoAAAcPz4cQA37mLdfMfq5MmT+O6774y+nfXll1+isLAQjzzyCFQqFTQaDRYtWoRp06Y12rUgIiIiy2LWEDV06FBcuHABc+bMgVarRUBAANLT06XF4/n5+bCy+t/dlF69emHTpk2YNWsWZs6cCT8/P6SlpaFz585Sn+3bt0shDACGDRsGAEhMTMTcuXOl9rVr16Jt27YICwurNi9bW1usXr0aU6dOhRAC999/v/R1DERERERAE1hYPmnSpBrfvtu7d2+1tiFDhmDIkCE1jhcdHY3o6Og6j7to0SIsWrTI6LaIiAhERETUOQYRERHdu8z+a1+IiIiILBFDFBEREZEMDFFEREREMjBEEREREcnAEEVEREQkA0MUERERkQwMUUREREQyMEQRERERycAQRURERCQDQxQRERGRDAxRRERERDIwRBERERHJwBBFREREJANDFBEREZEMDFFEREREMjBEEREREcnAEEVEREQkA0MUERERkQwMUUREREQyMEQRERERycAQRURERCQDQxQRERGRDAxRRERERDIwRBERERHJwBBFREREJANDFBEREZEMDFFEREREMjBEEREREcnAEEVEREQkA0MUERERkQwMUUREREQyMEQRERERycAQRURERCQDQxQRERGRDAxRRERERDIwRBERERHJwBBFREREJANDFBEREZEMDFFEREREMjBEEREREclg9hC1evVq+Pj4QKVSISgoCPv376+1/5YtW9ChQweoVCr4+/tj586dBtu3bduGsLAwuLm5QaFQIC8vr9oYffr0gUKhMHi8+OKLBn3y8/MRGRkJBwcHtGrVCtOnT0dFRcVtny8RERHdHcwaojZv3oz4+HgkJibi4MGD6Nq1K8LDw1FUVGS0/759+zB8+HDExsYiNzcXUVFRiIqKwpEjR6Q+JSUlCAkJwZtvvlnrsceNG4fz589LjyVLlkjbKisrERkZibKyMuzbtw/r16/HunXrMGfOHNOcOBEREVk8s4ao5cuXY9y4cYiJiUGnTp2QnJwMBwcHrF271mj/lStXIiIiAtOnT0fHjh2xYMECdO/eHatWrZL6jBo1CnPmzEFoaGitx3ZwcIBarZYezs7O0raMjAz88ssv2LBhAwICAtC/f38sWLAAq1evRllZmWlOnoiIiCyajbkOXFZWhpycHCQkJEhtVlZWCA0NRVZWltF9srKyEB8fb9AWHh6OtLS0Bh9/48aN2LBhA9RqNZ5++mnMnj0bDg4O0nH8/f3h4eFhcJwJEybg6NGj6Natm9ExS0tLUVpaKj3X6XQAgPLycpSXlzd4jjWpGquuMW0U+nqPRY2jvrUi82OtLAvrZTkssVb1navZQtTFixdRWVlpEFQAwMPDA8eOHTO6j1arNdpfq9U26NgvvPACvL290bp1axw6dAivvfYajh8/jm3bttV6nKptNUlKSsK8efOqtWdkZEgBzZQ0Gk2t24e0qnuMW9eUUeOoq1bUdLBWloX1shyWVKtr167Vq5/ZQpQ5jR8/Xvp/f39/eHp6om/fvjh16hTat28ve9yEhASDO2U6nQ5eXl4ICwszeLvwdpWXl0Oj0aBfv36wtbWtsV/MutoX6QNASnRPk82Lqqtvrcj8WCvLwnpZDkusVdU7SXUxW4hyd3eHtbU1CgsLDdoLCwuhVquN7qNWqxvUv76CgoIAACdPnkT79u2hVqurfUqw6ri1HcvOzg52dnbV2m1tbRvlhVPXuBWi7iVvlvKCtnSN9Rog02OtLAvrZTksqVb1nafZFpYrlUoEBgYiMzNTatPr9cjMzERwcLDRfYKDgw36AzduD9bUv76qvgbB09NTOs7hw4cNPiWo0Wjg7OyMTp063daxiIiI6O5g1rfz4uPjMWbMGPTo0QM9e/bEihUrUFJSgpiYGADA6NGj0aZNGyQlJQEA4uLi0Lt3byxbtgyRkZFITU3FgQMHsGbNGmnMS5cuIT8/HwUFBQCA48ePA4D0KbxTp05h06ZNGDBgANzc3HDo0CFMnToVjz/+OLp06QIACAsLQ6dOnTBq1CgsWbIEWq0Ws2bNwsSJE43eaSIiIqJ7j1lD1NChQ3HhwgXMmTMHWq0WAQEBSE9PlxZx5+fnw8rqfzfLevXqhU2bNmHWrFmYOXMm/Pz8kJaWhs6dO0t9tm/fLoUwABg2bBgAIDExEXPnzoVSqcSuXbukwObl5YVnn30Ws2bNkvaxtrbGjh07MGHCBAQHB8PR0RFjxozB/PnzG/uSEBERkYUw+8LySZMmYdKkSUa37d27t1rbkCFDMGTIkBrHi46ORnR0dI3bvby88O2339Y5L29vb35yjYiIiGpk9l/7QkRERGSJGKKIiIiIZGCIIiIiIpKBIYqIiIhIBoYoIiIiIhkYooiIiIhkYIgiIiIikoEhioiIiEgGhigiIiIiGRiiiIiIiGRgiCIiIiKSgSGKiIiISAaGKCIiIiIZGKKIiIiIZGCIIiIiIpKBIYqIiIhIBoYoIiIiIhkYooiIiIhkYIgiIiIikoEhioiIiEgGhigiIiIiGRiiiIiIiGRgiCIiIiKSgSGKiIiISAaGKCIiIiIZGKKIiIiIZGCIIiIiIpKBIYqIiIhIBoYoIiIiIhkYooiIiIhkYIgiIiIikoEhioiIiEgGhigiIiIiGRiiiIiIiGRgiCIiIiKSgSGKiIiISAaGKCIiIiIZGKKIiIiIZGCIIiIiIpLB7CFq9erV8PHxgUqlQlBQEPbv319r/y1btqBDhw5QqVTw9/fHzp07DbZv27YNYWFhcHNzg0KhQF5ensH2S5cu4eWXX8aDDz4Ie3t7tGvXDpMnT0ZxcbFBP4VCUe2RmppqknMmIiIiy2fWELV582bEx8cjMTERBw8eRNeuXREeHo6ioiKj/fft24fhw4cjNjYWubm5iIqKQlRUFI4cOSL1KSkpQUhICN58802jYxQUFKCgoABvvfUWjhw5gnXr1iE9PR2xsbHV+qakpOD8+fPSIyoqyiTnTURERJbPxpwHX758OcaNG4eYmBgAQHJyMr766iusXbsWM2bMqNZ/5cqViIiIwPTp0wEACxYsgEajwapVq5CcnAwAGDVqFADgzJkzRo/ZuXNnbN26VXrevn17LFy4ECNHjkRFRQVsbP53SVxdXaFWq01yrkRERHR3MVuIKisrQ05ODhISEqQ2KysrhIaGIisry+g+WVlZiI+PN2gLDw9HWlrabc2luLgYzs7OBgEKACZOnIixY8fivvvuw4svvoiYmBgoFIoaxyktLUVpaan0XKfTAQDKy8tRXl5+W3O8WdVYdY1po9DXeyxqHPWtFZkfa2VZWC/LYYm1qu9czRaiLl68iMrKSnh4eBi0e3h44NixY0b30Wq1RvtrtdrbmseCBQswfvx4g/b58+fjySefhIODAzIyMvDSSy/h6tWrmDx5co1jJSUlYd68edXaMzIy4ODgIHuONdFoNLVuH9Kq7jFuXVNGjaOuWlHTwVpZFtbLclhSra5du1avfmZ9O8/cdDodIiMj0alTJ8ydO9dg2+zZs6X/79atG0pKSrB06dJaQ1RCQoLBnTKdTgcvLy+EhYXB2dnZZPMuLy+HRqNBv379YGtrW2O/mHW1L9IHgJToniabF1VX31qR+bFWloX1shyWWKuqd5LqYrYQ5e7uDmtraxQWFhq0FxYW1rgOSa1WN6h/ba5cuYKIiAg0a9YMn3/+eZ2FDQoKwoIFC1BaWgo7Ozujfezs7Ixus7W1bZQXTl3jVoi6PzcwKuVAnX1Sxwc3aF5UXWO9Bsj0WCvLwnpZDkuqVX3nabZP5ymVSgQGBiIzM1Nq0+v1yMzMRHCw8R/awcHBBv2BG7cHa+pfE51Oh7CwMCiVSmzfvh0qlarOffLy8tC8efMaAxQRERHdW8z6dl58fDzGjBmDHj16oGfPnlixYgVKSkqkT+uNHj0abdq0QVJSEgAgLi4OvXv3xrJlyxAZGYnU1FQcOHAAa9askca8dOkS8vPzUVBQAAA4fvw4gBt3sdRqtRSgrl27hg0bNkCn00m37Vq2bAlra2t8+eWXKCwsxCOPPAKVSgWNRoNFixZh2rRpd/LyEBERURNm1hA1dOhQXLhwAXPmzIFWq0VAQADS09OlxeP5+fmwsvrfzbJevXph06ZNmDVrFmbOnAk/Pz+kpaWhc+fOUp/t27dLIQwAhg0bBgBITEzE3LlzcfDgQWRnZwMA7r//foP5nD59Gj4+PrC1tcXq1asxdepUCCFw//33S1/HQERERAQ0gYXlkyZNwqRJk4xu27t3b7W2IUOGYMiQITWOFx0djejo6Bq39+nTB0KIWucUERGBiIiIWvs0BTHr9tdr3RMRERGZHn8CExEREcnAEEVEREQkA0MUERERkQwMUUREREQyMEQRERERycAQRURERCQDQxQRERGRDAxRRERERDIwRBERERHJwBBFREREJANDFBEREZEMDFFEREREMjBEEREREcnAEEVEREQkA0MUERERkQwMUUREREQyMEQRERERycAQRURERCQDQxQRERGRDAxRRERERDIwRBERERHJwBBFREREJANDFBEREZEMDFFEREREMjBEEREREcnAEEVEREQkg6wQ9fvvv5t6HkREREQWRVaIuv/++/HEE09gw4YNuH79uqnnRERERNTkyQpRBw8eRJcuXRAfHw+1Wo3/+7//w/79+009NyIiIqImS1aICggIwMqVK1FQUIC1a9fi/PnzCAkJQefOnbF8+XJcuHDB1PMkIiIialJua2G5jY0NBg8ejC1btuDNN9/EyZMnMW3aNHh5eWH06NE4f/68qeZJRERE1KTcVog6cOAAXnrpJXh6emL58uWYNm0aTp06BY1Gg4KCAgwaNMhU8yQiIiJqUmzk7LR8+XKkpKTg+PHjGDBgAD755BMMGDAAVlY3Mpmvry/WrVsHHx8fU86ViIiIqMmQFaLef/99/Otf/0J0dDQ8PT2N9mnVqhU+/vjj25ocERERUVMlK0SdOHGizj5KpRJjxoyRMzwRERFRkydrTVRKSgq2bNlSrX3Lli1Yv379bU+KiIiIqKmTFaKSkpLg7u5erb1Vq1ZYtGjRbU+KiIiIqKmTFaLy8/Ph6+tbrd3b2xv5+fm3PSkiIiKipk5WiGrVqhUOHTpUrf3nn3+Gm5vbbU+KiIiIqKmTFaKGDx+OyZMnY8+ePaisrERlZSV2796NuLg4DBs2rEFjrV69Gj4+PlCpVAgKCqrz18ds2bIFHTp0gEqlgr+/P3bu3Gmwfdu2bQgLC4ObmxsUCgXy8vKqjXH9+nVMnDgRbm5ucHJywrPPPovCwkKDPvn5+YiMjISDgwNatWqF6dOno6KiokHnRkRERHcvWSFqwYIFCAoKQt++fWFvbw97e3uEhYXhySefbNCaqM2bNyM+Ph6JiYk4ePAgunbtivDwcBQVFRntv2/fPgwfPhyxsbHIzc1FVFQUoqKicOTIEalPSUkJQkJC8Oabb9Z43KlTp+LLL7/Eli1b8O2336KgoACDBw+WtldWViIyMhJlZWXYt28f1q9fj3Xr1mHOnDn1PjciIiK6uymEEELuzr/99ht+/vln2Nvbw9/fH97e3g3aPygoCA8//DBWrVoFANDr9fDy8sLLL7+MGTNmVOs/dOhQlJSUYMeOHVLbI488goCAACQnJxv0PXPmDHx9fZGbm4uAgACpvbi4GC1btsSmTZvw3HPPAQCOHTuGjh07IisrC4888gi+/vprPPXUUygoKICHhwcAIDk5Ga+99houXLgApVJZr/PT6XRwcXFBcXExnJ2dG3RtalNeXo6dO3diS5E7KsRtfel8vaSOD270Y9ytqmo1YMAA2Nramns6VAvWyrKwXpbDEmtV35/fsr4nqsoDDzyABx54QNa+ZWVlyMnJQUJCgtRmZWWF0NBQZGVlGd0nKysL8fHxBm3h4eFIS0ur93FzcnJQXl6O0NBQqa1Dhw5o166dFKKysrLg7+8vBaiq40yYMAFHjx5Ft27djI5dWlqK0tJS6blOpwNw4wVUXl5e7znWpWosG4XeZGPW53jUcFXXjtew6WOtLAvrZTkssVb1nausEFVZWYl169YhMzMTRUVF0OsNf5jv3r27zjEuXryIyspKg6ACAB4eHjh27JjRfbRardH+Wq223nPXarVQKpVwdXWtcZyajlO1rSZJSUmYN29etfaMjAw4ODjUe4719UzLSyYf05hb151Rw2k0GnNPgeqJtbIsrJflsKRaXbt2rV79ZIWouLg4rFu3DpGRkejcuTMUCoWcYe46CQkJBnfKdDodvLy8EBYWZvK38zQaDT6/0OKOvJ2XEt2z0Y9xt6qqVb9+/SzmNva9irWyLKyX5bDEWlW9k1QXWSEqNTUVn376KQYMGCBndwCAu7s7rK2tq30qrrCwEGq12ug+arW6Qf1rGqOsrAyXL182uBt18zhqtbrapwSrjlvbsezs7GBnZ1et3dbWtlFeOBXC6o6EKEt50TdljfUaINNjrSwL62U5LKlW9Z2nrJ/ASqUS999/v5xdDcYIDAxEZmam1KbX65GZmYngYOMLmYODgw36AzduD9bU35jAwEDY2toajHP8+HHk5+dL4wQHB+Pw4cMGnxLUaDRwdnZGp06d6n0sIiIiunvJuhP1yiuvYOXKlVi1atVtvZUXHx+PMWPGoEePHujZsydWrFiBkpISxMTEAABGjx6NNm3aICkpCcCNtxF79+6NZcuWITIyEqmpqThw4ADWrFkjjXnp0iXk5+ejoKAAwI2ABNy4g6RWq+Hi4oLY2FjEx8ejRYsWcHZ2xssvv4zg4GA88sgjAICwsDB06tQJo0aNwpIlS6DVajFr1ixMnDjR6J0mIiIiuvfIClHff/899uzZg6+//hoPPfRQtdte27Ztq9c4Q4cOxYULFzBnzhxotVoEBAQgPT1dWsSdn58PK6v/3Szr1asXNm3ahFmzZmHmzJnw8/NDWloaOnfuLPXZvn27FMIASF/+mZiYiLlz5wIA3n77bVhZWeHZZ59FaWkpwsPD8d5770n7WFtbY8eOHZgwYQKCg4Ph6OiIMWPGYP78+Q27UERERHTXkhWiXF1d8cwzz5hkApMmTcKkSZOMbtu7d2+1tiFDhmDIkCE1jhcdHY3o6Ohaj6lSqbB69WqsXr26xj7e3t78VBoRERHVSFaISklJMfU8iIiIiCyK7I92VVRUYNeuXfjggw9w5coVAEBBQQGuXr1qsskRERERNVWy7kSdPXsWERERyM/PR2lpKfr164dmzZrhzTffRGlpabVfwUJERER0t5F1JyouLg49evTA33//DXt7e6n9mWeeqfYVBERERER3I1l3ov773/9i37591X4Rr4+PD86dO2eSiRERERE1ZbLuROn1elRWVlZr//PPP9GsWbPbnhQRERFRUycrRIWFhWHFihXSc4VCgatXryIxMfG2fhUMERERkaWQ9XbesmXLEB4ejk6dOuH69et44YUXcOLECbi7u+M///mPqedIRERE1OTIClFt27bFzz//jNTUVBw6dAhXr15FbGwsRowYYbDQnIiIiOhuJStEAYCNjQ1GjhxpyrkQERERWQxZIeqTTz6pdfvo0aNlTYaIiIjIUsgKUXFxcQbPy8vLce3aNSiVSjg4ODBEERER0V1P1qfz/v77b4PH1atXcfz4cYSEhHBhOREREd0TZP/uvFv5+flh8eLF1e5SEREREd2NTBaigBuLzQsKCkw5JBEREVGTJGtN1Pbt2w2eCyFw/vx5rFq1Co8++qhJJkZERETUlMkKUVFRUQbPFQoFWrZsiSeffBLLli0zxbyIiIiImjRZIUqv15t6HkREREQWxaRrooiIiIjuFbLuRMXHx9e77/Lly+UcgoiIiKhJkxWicnNzkZubi/Lycjz44IMAgN9++w3W1tbo3r271E+hUJhmlkRERERNjKwQ9fTTT6NZs2ZYv349mjdvDuDGF3DGxMTgsccewyuvvGLSSRIRERE1NbLWRC1btgxJSUlSgAKA5s2b44033uCn84iIiOieICtE6XQ6XLhwoVr7hQsXcOXKldueFBEREVFTJytEPfPMM4iJicG2bdvw559/4s8//8TWrVsRGxuLwYMHm3qORERERE2OrDVRycnJmDZtGl544QWUl5ffGMjGBrGxsVi6dKlJJ0hERETUFMkKUQ4ODnjvvfewdOlSnDp1CgDQvn17ODo6mnRyRERERE3VbX3Z5vnz53H+/Hn4+fnB0dERQghTzYuIiIioSZMVov766y/07dsXDzzwAAYMGIDz588DAGJjY/n1BkRERHRPkBWipk6dCltbW+Tn58PBwUFqHzp0KNLT0002OSIiIqKmStaaqIyMDHzzzTdo27atQbufnx/Onj1rkokRERERNWWy7kSVlJQY3IGqcunSJdjZ2d32pIiIiIiaOlkh6rHHHsMnn3wiPVcoFNDr9ViyZAmeeOIJk02OiIiIqKmS9XbekiVL0LdvXxw4cABlZWV49dVXcfToUVy6dAk//PCDqedIRERE1OTIuhPVuXNn/PbbbwgJCcGgQYNQUlKCwYMHIzc3F+3btzf1HImIiIianAbfiSovL0dERASSk5Px+uuvN8aciIiIiJq8Bt+JsrW1xaFDhxpjLkREREQWQ9bbeSNHjsTHH39s6rkQERERWQxZC8srKiqwdu1a7Nq1C4GBgdV+Z97y5ctNMjkiIiKipqpBd6J+//136PV6HDlyBN27d0ezZs3w22+/ITc3V3rk5eU1eBKrV6+Gj48PVCoVgoKCsH///lr7b9myBR06dIBKpYK/vz927txpsF0IgTlz5sDT0xP29vYIDQ3FiRMnpO179+6FQqEw+vjpp58AAGfOnDG6/ccff2zw+REREdHdp0Ehys/PDxcvXsSePXuwZ88etGrVCqmpqdLzPXv2YPfu3Q2awObNmxEfH4/ExEQcPHgQXbt2RXh4OIqKioz237dvH4YPH47Y2Fjk5uYiKioKUVFROHLkiNRnyZIleOedd5CcnIzs7Gw4OjoiPDwc169fBwD06tVL+uXJVY+xY8fC19cXPXr0MDjerl27DPoFBgY26PyIiIjo7tSgECWEMHj+9ddfo6Sk5LYmsHz5cowbNw4xMTHo1KkTkpOT4eDggLVr1xrtv3LlSkRERGD69Ono2LEjFixYgO7du2PVqlXSHFesWIFZs2Zh0KBB6NKlCz755BMUFBQgLS0NAKBUKqFWq6WHm5sbvvjiC8TExEChUBgcz83NzaCvra3tbZ0vERER3R1krYmqcmuoaqiysjLk5OQgISFBarOyskJoaCiysrKM7pOVlYX4+HiDtvDwcCkgnT59GlqtFqGhodJ2FxcXBAUFISsrC8OGDas25vbt2/HXX38hJiam2raBAwfi+vXreOCBB/Dqq69i4MCBNZ5PaWkpSktLpec6nQ7Aja+FKC8vr3G/hqoay0ahN9mY9TkeNVzVteM1bPpYK8vCelkOS6xVfefaoBBVtS7o1ja5Ll68iMrKSnh4eBi0e3h44NixY0b30Wq1RvtrtVppe1VbTX1u9fHHHyM8PNzgFyo7OTlh2bJlePTRR2FlZYWtW7ciKioKaWlpNQappKQkzJs3r1p7RkaG0d81eLueaXnJ5GMac+uaM2o4jUZj7ilQPbFWloX1shyWVKtr167Vq1+DQpQQAtHR0dIvGb5+/TpefPHFap/O27ZtW0OGNas///wT33zzDT799FODdnd3d4M7Xg8//DAKCgqwdOnSGkNUQkKCwT46nQ5eXl4ICwuDs7OzyeZcXl4OjUaDzy+0QIWQ9S0VJpcS3dPcU2iSqmrVr18/vhXcxLFWloX1shyWWKuqd5Lq0qAQNWbMGIPnI0eObMju1bi7u8Pa2hqFhYUG7YWFhVCr1Ub3UavVtfav+m9hYSE8PT0N+gQEBFQbLyUlBW5ubrW+TVclKCio1iRtZ2cnBcyb2draNsoLp0JYNZkQZSl/MMylsV4DZHqslWVhvSyHJdWqvvNsUIhKSUmRNZmaKJVKBAYGIjMzE1FRUQAAvV6PzMxMTJo0yeg+wcHByMzMxJQpU6Q2jUaD4OBgAICvry/UajUyMzOl0KTT6ZCdnY0JEyYYjCWEQEpKCkaPHl2vC5aXl2cQzIiIiOjedVsLy00hPj4eY8aMQY8ePdCzZ0+sWLECJSUl0iLv0aNHo02bNkhKSgIAxMXFoXfv3li2bBkiIyORmpqKAwcOYM2aNQBurNGaMmUK3njjDfj5+cHX1xezZ89G69atpaBWZffu3Th9+jTGjh1bbV7r16+HUqlEt27dANx4i3Lt2rX46KOPGvFqEBERkaUwe4gaOnQoLly4gDlz5kCr1SIgIADp6enSwvD8/HxYWf3vLatevXph06ZNmDVrFmbOnAk/Pz+kpaWhc+fOUp9XX30VJSUlGD9+PC5fvoyQkBCkp6dDpVIZHPvjjz9Gr1690KFDB6NzW7BgAc6ePQsbGxt06NABmzdvxnPPPdcIV4GIiIgsjULc7vcUUI10Oh1cXFxQXFxs8oXlO3fuxJYi9yazJip1fLC5p9AkVdVqwIABFrMW4F7FWlkW1styWGKt6vvzu2n8BCYiIiKyMAxRRERERDIwRBERERHJwBBFREREJANDFBEREZEMDFFEREREMjBEEREREcnAEEVEREQkA0MUERERkQwMUUREREQyMEQRERERycAQRURERCQDQxQRERGRDAxRRERERDIwRBERERHJwBBFREREJANDFBEREZEMDFFEREREMjBEEREREcnAEEVEREQkA0MUERERkQwMUUREREQyMEQRERERycAQRURERCQDQxQRERGRDAxRRERERDIwRBERERHJwBBFREREJANDFBEREZEMDFFEREREMjBEEREREcnAEEVEREQkA0MUERERkQwMUUREREQyMEQRERERycAQRURERCQDQxQRERGRDAxRRERERDIwRBERERHJ0CRC1OrVq+Hj4wOVSoWgoCDs37+/1v5btmxBhw4doFKp4O/vj507dxpsF0Jgzpw58PT0hL29PUJDQ3HixAmDPj4+PlAoFAaPxYsXG/Q5dOgQHnvsMahUKnh5eWHJkiWmOWEiIiKyeGYPUZs3b0Z8fDwSExNx8OBBdO3aFeHh4SgqKjLaf9++fRg+fDhiY2ORm5uLqKgoREVF4ciRI1KfJUuW4J133kFycjKys7Ph6OiI8PBwXL9+3WCs+fPn4/z589Lj5ZdflrbpdDqEhYXB29sbOTk5WLp0KebOnYs1a9Y0zoUgIiIii2L2ELV8+XKMGzcOMTEx6NSpE5KTk+Hg4IC1a9ca7b9y5UpERERg+vTp6NixIxYsWIDu3btj1apVAG7chVqxYgVmzZqFQYMGoUuXLvjkk09QUFCAtLQ0g7GaNWsGtVotPRwdHaVtGzduRFlZGdauXYuHHnoIw4YNw+TJk7F8+fJGuxZERERkOWzMefCysjLk5OQgISFBarOyskJoaCiysrKM7pOVlYX4+HiDtvDwcCkgnT59GlqtFqGhodJ2FxcXBAUFISsrC8OGDZPaFy9ejAULFqBdu3Z44YUXMHXqVNjY2EjHefzxx6FUKg2O8+abb+Lvv/9G8+bNq82ttLQUpaWl0nOdTgcAKC8vR3l5eX0vS52qxrJR6E025u0y5fndTaquC69P08daWRbWy3JYYq3qO1ezhqiLFy+isrISHh4eBu0eHh44duyY0X20Wq3R/lqtVtpe1VZTHwCYPHkyunfvjhYtWmDfvn1ISEjA+fPnpTtNWq0Wvr6+1cao2mYsRCUlJWHevHnV2jMyMuDg4GD0fG7HMy0vmXxMuW5dl0aGNBqNuadA9cRaWRbWy3JYUq2uXbtWr35mDVHmdPPdrC5dukCpVOL//u//kJSUBDs7O1ljJiQkGIyr0+ng5eWFsLAwODs73/acq5SXl0Oj0eDzCy1QIcz+jiwAICW6p7mn0CRV1apfv36wtbU193SoFqyVZWG9LIcl1qrqnaS6mDVEubu7w9raGoWFhQbthYWFUKvVRvdRq9W19q/6b2FhITw9PQ36BAQE1DiXoKAgVFRU4MyZM3jwwQdrPM7Nx7iVnZ2d0QBma2vbKC+cCmHVZEKUpfzBMJfGeg2Q6bFWloX1shyWVKv6ztOsP4GVSiUCAwORmZkpten1emRmZiI4ONjoPsHBwQb9gRu3CKv6+/r6Qq1WG/TR6XTIzs6ucUwAyMvLg5WVFVq1aiUd57vvvjN4X1Sj0eDBBx80+lYeERER3VvMfhsjPj4eH374IdavX49ff/0VEyZMQElJCWJiYgAAo0ePNlh4HhcXh/T0dCxbtgzHjh3D3LlzceDAAUyaNAkAoFAoMGXKFLzxxhvYvn07Dh8+jNGjR6N169aIiooCcGPR+IoVK/Dzzz/j999/x8aNGzF16lSMHDlSCkgvvPAClEolYmNjcfToUWzevBkrV66stqidiIiI7k1mXxM1dOhQXLhwAXPmzIFWq0VAQADS09OlRdz5+fmwsvpf1uvVqxc2bdqEWbNmYebMmfDz80NaWho6d+4s9Xn11VdRUlKC8ePH4/LlywgJCUF6ejpUKhWAG2+7paamYu7cuSgtLYWvry+mTp1qEJBcXFyQkZGBiRMnIjAwEO7u7pgzZw7Gjx9/h64MERERNWVmD1EAMGnSJOlO0q327t1brW3IkCEYMmRIjeMpFArMnz8f8+fPN7q9e/fu+PHHH+ucV5cuXfDf//63zn5ERER07zH723lEREREloghioiIiEgGhigiIiIiGRiiiIiIiGRgiCIiIiKSgSGKiIiISAaGKCIiIiIZGKKIiIiIZGCIIiIiIpKBIYqIiIhIBoYoIiIiIhkYooiIiIhkYIgiIiIikoEhioiIiEgGG3NPgO4Ow9Zk1dkndXzwHZgJERHRncE7UUREREQyMEQRERERycAQRURERCQDQxQRERGRDAxRRERERDIwRBERERHJwBBFREREJANDFBEREZEMDFFEREREMjBEEREREcnAEEVEREQkA0MUERERkQwMUUREREQyMEQRERERycAQRURERCQDQxQRERGRDAxRRERERDIwRBERERHJwBBFREREJANDFBEREZEMDFFEREREMjBEEREREcnAEEVEREQkA0MUERERkQxNIkStXr0aPj4+UKlUCAoKwv79+2vtv2XLFnTo0AEqlQr+/v7YuXOnwXYhBObMmQNPT0/Y29sjNDQUJ06ckLafOXMGsbGx8PX1hb29Pdq3b4/ExESUlZUZ9FEoFNUeP/74o2lPnoiIiCyS2UPU5s2bER8fj8TERBw8eBBdu3ZFeHg4ioqKjPbft28fhg8fjtjYWOTm5iIqKgpRUVE4cuSI1GfJkiV45513kJycjOzsbDg6OiI8PBzXr18HABw7dgx6vR4ffPABjh49irfffhvJycmYOXNmtePt2rUL58+flx6BgYGNcyGIiIjIopg9RC1fvhzjxo1DTEwMOnXqhOTkZDg4OGDt2rVG+69cuRIRERGYPn06OnbsiAULFqB79+5YtWoVgBt3oVasWIFZs2Zh0KBB6NKlCz755BMUFBQgLS0NABAREYGUlBSEhYXhvvvuw8CBAzFt2jRs27at2vHc3NygVqulh62tbaNdCyIiIrIcZg1RZWVlyMnJQWhoqNRmZWWF0NBQZGVlGd0nKyvLoD8AhIeHS/1Pnz4NrVZr0MfFxQVBQUE1jgkAxcXFaNGiRbX2gQMHolWrVggJCcH27dsbdH5ERER097Ix58EvXryIyspKeHh4GLR7eHjg2LFjRvfRarVG+2u1Wml7VVtNfW518uRJvPvuu3jrrbekNicnJyxbtgyPPvoorKyssHXrVkRFRSEtLQ0DBw40Ok5paSlKS0ul5zqdDgBQXl6O8vJyo/vIUTWWjUJvsjHvBFNeA0tRdc734rlbGtbKsrBelsMSa1XfuZo1RDUF586dQ0REBIYMGYJx48ZJ7e7u7oiPj5eeP/zwwygoKMDSpUtrDFFJSUmYN29etfaMjAw4ODiYfO7PtLxk8jEb060fALiXaDQac0+B6om1siysl+WwpFpdu3atXv3MGqLc3d1hbW2NwsJCg/bCwkKo1Wqj+6jV6lr7V/23sLAQnp6eBn0CAgIM9isoKMATTzyBXr16Yc2aNXXONygoqNYXQUJCgkHw0ul08PLyQlhYGJydnescv77Ky8uh0Wjw+YUWqBBmX9ZWbynRPc09hTuuqlb9+vXjeromjrWyLKyX5bDEWlW9k1QXs4YopVKJwMBAZGZmIioqCgCg1+uRmZmJSZMmGd0nODgYmZmZmDJlitSm0WgQHBwMAPD19YVarUZmZqYUmnQ6HbKzszFhwgRpn3PnzuGJJ55AYGAgUlJSYGVVdxjJy8szCGa3srOzg52dXbV2W1vbRnnhVAgriwpRo1IO1NkndXzwHZjJnddYrwEyPdbKsrBelsOSalXfeZr97bz4+HiMGTMGPXr0QM+ePbFixQqUlJQgJiYGADB69Gi0adMGSUlJAIC4uDj07t0by5YtQ2RkJFJTU3HgwAHpTpJCocCUKVPwxhtvwM/PD76+vpg9ezZat24tBbVz586hT58+8Pb2xltvvYULFy5I86m6k7V+/XoolUp069YNALBt2zasXbsWH3300Z26NERERNSEmT1EDR06FBcuXMCcOXOg1WoREBCA9PR0aWF4fn6+wV2iXr16YdOmTZg1axZmzpwJPz8/pKWloXPnzlKfV199FSUlJRg/fjwuX76MkJAQpKenQ6VSAbhx5+rkyZM4efIk2rZtazAfIYT0/wsWLMDZs2dhY2ODDh06YPPmzXjuueca83IQERGRhVCIm1MDmZROp4OLiwuKi4tNviZq586d2FLkblFv59XH3fZ2XlWtBgwYYDG3se9VrJVlYb0shyXWqr4/v++un8BEREREdwhDFBEREZEMDFFEREREMjBEEREREcnAEEVEREQkA0MUERERkQwMUUREREQyMEQRERERycAQRURERCQDQxQRERGRDAxRRERERDIwRBERERHJwBBFREREJANDFBEREZEMDFFEREREMjBEEREREcnAEEVEREQkg425J0B0s2Frsurskzo++A7MhIiIqHa8E0VEREQkA0MUERERkQwMUUREREQyMEQRERERycAQRURERCQDQxQRERGRDAxRRERERDIwRBERERHJwBBFREREJANDFBEREZEM/LUvZHH4q2GIiKgp4J0oIiIiIhkYooiIiIhkYIgiIiIikoEhioiIiEgGhigiIiIiGfjpPLor8RN8RETU2HgnioiIiEgGhigiIiIiGRiiiIiIiGTgmii6Z3HdFBER3Y4mcSdq9erV8PHxgUqlQlBQEPbv319r/y1btqBDhw5QqVTw9/fHzp07DbYLITBnzhx4enrC3t4eoaGhOHHihEGfS5cuYcSIEXB2doarqytiY2Nx9epVgz6HDh3CY489BpVKBS8vLyxZssQ0J0wWY9iarDofRER0bzJ7iNq8eTPi4+ORmJiIgwcPomvXrggPD0dRUZHR/vv27cPw4cMRGxuL3NxcREVFISoqCkeOHJH6LFmyBO+88w6Sk5ORnZ0NR0dHhIeH4/r161KfESNG4OjRo9BoNNixYwe+++47jB8/Xtqu0+kQFhYGb29v5OTkYOnSpZg7dy7WrFnTeBeDiIiILIZCCCHMOYGgoCA8/PDDWLVqFQBAr9fDy8sLL7/8MmbMmFGt/9ChQ1FSUoIdO3ZIbY888ggCAgKQnJwMIQRat26NV155BdOmTQMAFBcXw8PDA+vWrcOwYcPw66+/olOnTvjpp5/Qo0cPAEB6ejoGDBiAP//8E61bt8b777+P119/HVqtFkqlEgAwY8YMpKWl4dixY/U6N51OBxcXFxQXF8PZ2fm2rtPNysvLsXPnTmwpckeFMHsOplrYKPQY0uoiBgwYAFtbW3NPh2pR9eeKtbIMrJflsMRa1ffnt1nXRJWVlSEnJwcJCQlSm5WVFUJDQ5GVZfxtkqysLMTHxxu0hYeHIy0tDQBw+vRpaLVahIaGSttdXFwQFBSErKwsDBs2DFlZWXB1dZUCFACEhobCysoK2dnZeOaZZ5CVlYXHH39cClBVx3nzzTfx999/o3nz5qa4BHSPiFm33ySBl2u0iIiaDrOGqIsXL6KyshIeHh4G7R4eHjXe7dFqtUb7a7VaaXtVW219WrVqZbDdxsYGLVq0MOjj6+tbbYyqbcZCVGlpKUpLS6XnxcXFAG6svyovLzd6PnKUl5fj2rVr0F+/AsE7UU2aXqE3aa2GvpNhglk1Pe+NCDT3FKQ/V3/99ZfF/Gv5XsZ6WQ5LrNWVK1cA3FhjXRt+Os+EkpKSMG/evGrtt4Yxurf8x9wTsACfxpl7BkRE1V25cgUuLi41bjdriHJ3d4e1tTUKCwsN2gsLC6FWq43uo1ara+1f9d/CwkJ4enoa9AkICJD63LpwvaKiApcuXTIYx9hxbj7GrRISEgzeatTr9bh06RLc3NygUCiM7iOHTqeDl5cX/vjjD5OutSLTY60sB2tlWVgvy2GJtRJC4MqVK2jdunWt/cwaopRKJQIDA5GZmYmoqCgAN4JHZmYmJk2aZHSf4OBgZGZmYsqUKVKbRqNBcPCNtSK+vr5Qq9XIzMyUQpNOp0N2djYmTJggjXH58mXk5OQgMPDG2wi7d++GXq9HUFCQ1Of1119HeXm5dPtRo9HgwQcfrHE9lJ2dHezs7AzaXF1dG3xd6svZ2dliXpD3OtbKcrBWloX1shyWVqva7kBJhJmlpqYKOzs7sW7dOvHLL7+I8ePHC1dXV6HVaoUQQowaNUrMmDFD6v/DDz8IGxsb8dZbb4lff/1VJCYmCltbW3H48GGpz+LFi4Wrq6v44osvxKFDh8SgQYOEr6+v+Oeff6Q+ERERolu3biI7O1t8//33ws/PTwwfPlzafvnyZeHh4SFGjRoljhw5IlJTU4WDg4P44IMP7sBVqV1xcbEAIIqLi809FaoDa2U5WCvLwnpZjru5VmYPUUII8e6774p27doJpVIpevbsKX788UdpW+/evcWYMWMM+n/66afigQceEEqlUjz00EPiq6++Mtiu1+vF7NmzhYeHh7CzsxN9+/YVx48fN+jz119/ieHDhwsnJyfh7OwsYmJixJUrVwz6/PzzzyIkJETY2dmJNm3aiMWLF5v2xGW6m1+QdxvWynKwVpaF9bIcd3OtzP49UdRwpaWlSEpKQkJCQrW3D6lpYa0sB2tlWVgvy3E314ohioiIiEgGfskQERERkQwMUUREREQyMEQRERERycAQRURERCQDQ5SFWb16NXx8fKBSqRAUFIT9+/ebe0r3nKSkJDz88MNo1qwZWrVqhaioKBw/ftygz/Xr1zFx4kS4ubnByckJzz77bLVvwM/Pz0dkZCQcHBzQqlUrTJ8+HRUVFXfyVO45ixcvhkKhMPiyXtaq6Th37hxGjhwJNzc32Nvbw9/fHwcOHJC2CyEwZ84ceHp6wt7eHqGhoThx4oTBGJcuXcKIESPg7OwMV1dXxMbG4urVq3f6VO56lZWVmD17Nnx9fWFvb4/27dtjwYIFBr9r7p6olxm/XoEaKDU1VSiVSrF27Vpx9OhRMW7cOOHq6ioKCwvNPbV7Snh4uEhJSRFHjhwReXl5YsCAAaJdu3bi6tWrUp8XX3xReHl5iczMTHHgwAHxyCOPiF69eknbKyoqROfOnUVoaKjIzc0VO3fuFO7u7iIhIcEcp3RP2L9/v/Dx8RFdunQRcXFxUjtr1TRcunRJeHt7i+joaJGdnS1+//138c0334iTJ09KfRYvXixcXFxEWlqa+Pnnn8XAgQONfpFy165dxY8//ij++9//ivvvv9/gi5TJNBYuXCjc3NzEjh07xOnTp8WWLVuEk5OTWLlypdTnXqgXQ5QF6dmzp5g4caL0vLKyUrRu3VokJSWZcVZUVFQkAIhvv/1WCHHj2+5tbW3Fli1bpD6//vqrACCysrKEEELs3LlTWFlZSd/ML4QQ77//vnB2dhalpaV39gTuAVeuXBF+fn5Co9GI3r17SyGKtWo6XnvtNRESElLjdr1eL9RqtVi6dKnUdvnyZWFnZyf+85//CCGE+OWXXwQA8dNPP0l9vv76a6FQKMS5c+cab/L3oMjISPGvf/3LoG3w4MFixIgRQoh7p158O89ClJWVIScnB6GhoVKblZUVQkNDkZWVZcaZUXFxMQCgRYsWAICcnByUl5cb1KpDhw5o166dVKusrCz4+/vDw8ND6hMeHg6dToejR4/ewdnfGyZOnIjIyEiDmgCsVVOyfft29OjRA0OGDEGrVq3QrVs3fPjhh9L206dPQ6vVGtTKxcUFQUFBBrVydXVFjx49pD6hoaGwsrJCdnb2nTuZe0CvXr2QmZmJ3377DQDw888/4/vvv0f//v0B3Dv1MusvIKb6u3jxIiorKw3+IgcADw8PHDt2zEyzIr1ejylTpuDRRx9F586dAQBarRZKpbLaL5/28PCAVquV+hirZdU2Mp3U1FQcPHgQP/30U7VtrFXT8fvvv+P9999HfHw8Zs6ciZ9++gmTJ0+GUqnEmDFjpGttrBY316pVq1YG221sbNCiRQvWysRmzJgBnU6HDh06wNraGpWVlVi4cCFGjBgBAPdMvRiiiG7DxIkTceTIEXz//ffmngoZ8ccffyAuLg4ajQYqlcrc06Fa6PV69OjRA4sWLQIAdOvWDUeOHEFycjLGjBlj5tnRrT799FNs3LgRmzZtwkMPPYS8vDxMmTIFrVu3vqfqxbfzLIS7uzusra2rfWqosLAQarXaTLO6t02aNAk7duzAnj170LZtW6ldrVajrKwMly9fNuh/c63UarXRWlZtI9PIyclBUVERunfvDhsbG9jY2ODbb7/FO++8AxsbG3h4eLBWTYSnpyc6depk0NaxY0fk5+cD+N+1ru3vQLVajaKiIoPtFRUVuHTpEmtlYtOnT8eMGTMwbNgw+Pv7Y9SoUZg6dSqSkpIA3Dv1YoiyEEqlEoGBgcjMzJTa9Ho9MjMzERwcbMaZ3XuEEJg0aRI+//xz7N69G76+vgbbAwMDYWtra1Cr48ePIz8/X6pVcHAwDh8+bPAXiEajgbOzc7UfJCRf3759cfjwYeTl5UmPHj16YMSIEdL/s1ZNw6OPPlrtq0J+++03eHt7AwB8fX2hVqsNaqXT6ZCdnW1Qq8uXLyMnJ0fqs3v3buj1egQFBd2Bs7h3XLt2DVZWhhHC2toaer0ewD1UL3OvbKf6S01NFXZ2dmLdunXil19+EePHjxeurq4GnxqixjdhwgTh4uIi9u7dK86fPy89rl27JvV58cUXRbt27cTu3bvFgQMHRHBwsAgODpa2V31sPiwsTOTl5Yn09HTRsmVLfmz+Drj503lCsFZNxf79+4WNjY1YuHChOHHihNi4caNwcHAQGzZskPosXrxYuLq6ii+++EIcOnRIDBo0yOhH5rt16yays7PF999/L/z8/CzqI/OWYsyYMaJNmzbSVxxs27ZNuLu7i1dffVXqcy/UiyHKwrz77ruiXbt2QqlUip49e4off/zR3FO65wAw+khJSZH6/PPPP+Kll14SzZs3Fw4ODuKZZ54R58+fNxjnzJkzon///sLe3l64u7uLV155RZSXl9/hs7n33BqiWKum48svvxSdO3cWdnZ2okOHDmLNmjUG2/V6vZg9e7bw8PAQdnZ2om/fvuL48eMGff766y8xfPhw4eTkJJydnUVMTIy4cuXKnTyNe4JOpxNxcXGiXbt2QqVSifvuu0+8/vrrBl/7cS/USyHETV8vSkRERET1wjVRRERERDIwRBERERHJwBBFREREJANDFBEREZEMDFFEREREMjBEEREREcnAEEVEREQkA0MUEZEZREdHIyoqytzTIKLbwBBFRHc1c4eVM2fOQKFQIC8vz2xzIKLGwRBFREREJANDFBHds44cOYL+/fvDyckJHh4eGDVqFC5evCht79OnDyZPnoxXX30VLVq0gFqtxty5cw3GOHbsGEJCQqBSqdCpUyfs2rULCoUCaWlpAG78NnsA6NatGxQKBfr06WOw/1tvvQVPT0+4ublh4sSJKC8vb8xTJiITYogionvS5cuX8eSTT6Jbt244cOAA0tPTUVhYiOeff96g3/r16+Ho6Ijs7GwsWbIE8+fPh0ajAQBUVlYiKioKDg4OyM7Oxpo1a/D6668b7L9//34AwK5du3D+/Hls27ZN2rZnzx6cOnUKe/bswfr167Fu3TqsW7eucU+ciEzGxtwTICIyh1WrVqFbt25YtGiR1LZ27Vp4eXnht99+wwMPPAAA6NKlCxITEwEAfn5+WLVqFTIzM9GvXz9oNBqcOnUKe/fuhVqtBgAsXLgQ/fr1k8Zs2bIlAMDNzU3qU6V58+ZYtWoVrK2t0aFDB0RGRiIzMxPjxo1r1HMnItNgiCKie9LPP/+MPXv2wMnJqdq2U6dOGYSom3l6eqKoqAgAcPz4cXh5eRmEo549e9Z7Dg899BCsra0Nxj58+HCDzoOIzIchiojuSVevXsXTTz+NN998s9o2T09P6f9tbW0NtikUCuj1epPMoTHHJqLGxxBFRPek7t27Y+vWrfDx8YGNjby/Ch988EH88ccfKCwshIeHBwDgp59+MuijVCoB3Fg/RUR3Fy4sJ6K7XnFxMfLy8gwe48ePx6VLlzB8+HD89NNPOHXqFL755hvExMTUO/D069cP7du3x5gxY3Do0CH88MMPmDVrFoAbd5UAoFWrVrC3t5cWrhcXFzfaeRLRncUQRUR3vb1796Jbt24GjwULFuCHH35AZWUlwsLC4O/vjylTpsDV1RVWVvX7q9Ha2hppaWm4evUqHn74YYwdO1b6dJ5KpQIA2NjY4J133sEHH3yA1q1bY9CgQY12nkR0ZymEEMLckyAiulv88MMPCAkJwcmTJ9G+fXtzT4eIGhFDFBHRbfj888/h5OQEPz8/nDx5EnFxcWjevDm+//57c0+NiBoZF5YTEd2GK1eu4LXXXkN+fj7c3d0RGhqKZcuWmXtaRHQH8E4UERERkQxcWE5EREQkA0MUERERkQwMUUREREQyMEQRERERycAQRURERCQDQxQRERGRDAxRRERERDIwRBERERHJwBBFREREJMP/A3qFEDyp6hDbAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most token lengths are less than 200. So that should be a good block size"
      ],
      "metadata": {
        "id": "YeLV7wRCFcDU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "USmQWu4j-TAY"
      },
      "outputs": [],
      "source": [
        "# Constants and hyperparameters\n",
        "\n",
        "DROPOUT = 0.001\n",
        "\n",
        "BLOCK_SIZE = 200 # Maximum number of tokens passed / Context length\n",
        "BATCH_SIZE = 32\n",
        "VOCAB_SIZE = len(tokenizer)\n",
        "EMBEDDING_DIMS = 120\n",
        "NUMBER_OF_BLOCKS = 6\n",
        "NUMBER_OF_HEADS = 6\n",
        "EPOCHS = 300\n",
        "LEARNING_RATE = 3e-4\n",
        "\n",
        "TRAINING_DATA = True\n",
        "TEST_DATA = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom method to tokenize and encapsulate the settings inside.\n",
        "def tokenize(input, BLOCK_SIZE):\n",
        "    return tokenizer(input,\n",
        "                    truncation=True,\n",
        "                    max_length=BLOCK_SIZE,\n",
        "                    padding=\"longest\",\n",
        "                    add_special_tokens=True,\n",
        "                    return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "ui_IyyBwifrD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWPZKI2vg265",
        "outputId": "32300ed8-91fc-4e02-e0e3-0faae09ff990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([15496,   995,    11,   703,   389,   345,    30, 50256])\n",
            "['Hello', 'Ġworld', ',', 'Ġhow', 'Ġare', 'Ġyou', '?', '<|endoftext|>']\n",
            "Hello world, how are you?<|endoftext|>\n",
            "Hello world, how are you?\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ],
      "source": [
        "tokenized = tokenize(\"Hello world, how are you?\" + tokenizer.eos_token,BATCH_SIZE)\n",
        "ids = tokenized.input_ids\n",
        "ids = ids[0] #Batch 1\n",
        "print(ids)\n",
        "\n",
        "print(tokenizer.convert_ids_to_tokens(ids))\n",
        "print(tokenizer.decode(ids))\n",
        "print(tokenizer.decode(ids, skip_special_tokens=True))\n",
        "print(tokenized.attention_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNIBbdRX7HLY",
        "outputId": "c3103913-e976-4338-b997-bc53a69d75f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d496c3619d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "torch.manual_seed(1337)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3UMh3d4O7DT_"
      },
      "outputs": [],
      "source": [
        "# Dataset generation\n",
        "train_data = books[\"train\"]\n",
        "test_data = books[\"test\"]\n",
        "\n",
        "# returns token batches, and attention mask batch\n",
        "def batch_generator(is_training_data, BLOCK_SIZE, BATCH_SIZE):\n",
        "    dataset = train_data if is_training_data else test_data\n",
        "    starting_indices = torch.randint(len(dataset)-1, (BATCH_SIZE,))\n",
        "    x_batch = []\n",
        "    y_batch = []\n",
        "    x_attention_masks = []\n",
        "    y_attention_masks = []\n",
        "    for i in starting_indices:\n",
        "\n",
        "        x_batch.append(dataset[int(i)]['translation']['en'] + tokenizer.eos_token)\n",
        "        y_batch.append(dataset[int(i)]['translation']['fr'] + tokenizer.eos_token)\n",
        "\n",
        "    x_tokenized = tokenize(x_batch,BLOCK_SIZE)\n",
        "    y_tokenized = tokenize(y_batch,BLOCK_SIZE)\n",
        "\n",
        "    x_batch = x_tokenized.input_ids\n",
        "    y_batch = y_tokenized.input_ids\n",
        "\n",
        "    x_attention_masks = x_tokenized.attention_mask\n",
        "    y_attention_masks = y_tokenized.attention_mask\n",
        "\n",
        "    return x_batch.to(device), y_batch.to(device), x_attention_masks.to(device), y_attention_masks.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6SH-yxuFsEY"
      },
      "outputs": [],
      "source": [
        "x_batch, y_batch, x_attention_masks, y_attention_masks = batch_generator(True, BLOCK_SIZE, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBOKQtC8Fues",
        "outputId": "8637e849-6b57-4749-9660-7e62533047f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1537,  6159,  5395,  ..., 50257, 50257, 50257],\n",
            "        [  464,  2580,  2100,  ..., 50257, 50257, 50257],\n",
            "        [ 1870,  6451,   339,  ..., 50257, 50257, 50257],\n",
            "        ...,\n",
            "        [ 2202,   262,  2805,  ..., 50257, 50257, 50257],\n",
            "        [ 3856,   340,  7247,  ..., 50257, 50257, 50257],\n",
            "        [   50,   447,   247,  ..., 50257, 50257, 50257]], device='cuda:0')\n",
            "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(x_batch)\n",
        "print(x_attention_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-GFFE--F8Z_",
        "outputId": "2e648331-92fc-484d-c87e-4476873fa99d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   44, 15152,    11,  ..., 50257, 50257, 50257],\n",
            "        [ 3123,  1125,  2100,  ..., 50257, 50257, 50257],\n",
            "        [   36,    83,    11,  ..., 50257, 50257, 50257],\n",
            "        ...,\n",
            "        [35660,   269, 27083,  ..., 50257, 50257, 50257],\n",
            "        [   45,   516,  1582,  ..., 50257, 50257, 50257],\n",
            "        [ 1532,   339,  6834,  ..., 50257, 50257, 50257]], device='cuda:0')\n",
            "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(y_batch)\n",
        "print(y_attention_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "OLJwJ9HAN8-c"
      },
      "outputs": [],
      "source": [
        "# The real stuff here\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    BLOCK_SIZE = 120;                               # Default\n",
        "    DROPOUT = 0.1;\n",
        "\n",
        "    class AttentionHead(nn.Module):\n",
        "        def __init__(self, embedding_dims, head_dims):\n",
        "            super().__init__();\n",
        "            self.head_dims = head_dims\n",
        "\n",
        "            self.value_layer = nn.Linear(embedding_dims, head_dims)\n",
        "            self.query_layer = nn.Linear(embedding_dims, head_dims)\n",
        "            self.key_layer = nn.Linear(embedding_dims, head_dims)\n",
        "            self.register_buffer('tril', torch.tril(torch.ones(Transformer.BLOCK_SIZE, Transformer.BLOCK_SIZE)))\n",
        "            self.dropout = nn.Dropout(Transformer.DROPOUT)\n",
        "\n",
        "        def forward(self, input, encoder_output=None, causal_mask=True, padding_masks=None):\n",
        "            query = self.query_layer(input)         #(B, T, C) input but layer applies to C dimension vector slices as a batch of (B*T).\n",
        "\n",
        "            if encoder_output is None:              # Self Attention\n",
        "                key = self.key_layer(input)\n",
        "                value = self.value_layer(input)\n",
        "            else:                                   # Cross Attention\n",
        "                key = self.key_layer(encoder_output)\n",
        "                value = self.value_layer(encoder_output)\n",
        "\n",
        "            weights = query@key.transpose(-2, -1) * (self.head_dims)**0.5                           # (B, T_q, hs) @ (B, hs, T_k) -> (B, T_q, T_k)\n",
        "\n",
        "            _, T_q, T_k = weights.shape                                                               # We extract number of tokens here so the model isn't rigid and it can be any number.\n",
        "            if causal_mask:\n",
        "                weights = weights.masked_fill(self.tril[:T_q, :T_k] == 0, float('-inf'))\n",
        "\n",
        "            if padding_masks is not None:\n",
        "                weights = weights.masked_fill(padding_masks[:, None, :] == 0, float('-inf'))     # Equivalent to only masking the key values of padded tokens, and not the query. So that the token still remains present in the final embeddings formed for that token. But it does not communicate with any other token or affect them.\n",
        "\n",
        "            weights = F.softmax(weights, -1)                                                        # Or affinities #Includes all columns like weights[i, j, :]\n",
        "\n",
        "            weights = self.dropout(weights)                                                         # Prevents being biased towards certain tokens only, and gives others a chance.\n",
        "            return weights@value # (B, T, hs)\n",
        "\n",
        "\n",
        "    class MultiHeadAttention(nn.Module):\n",
        "        def __init__(self, embedding_dims, n_heads):\n",
        "            super().__init__();\n",
        "\n",
        "            head_dims = embedding_dims//n_heads\n",
        "            self.heads = nn.ModuleList([Transformer.AttentionHead(embedding_dims, head_dims) for _ in range(n_heads)])\n",
        "            self.projection = nn.Linear(embedding_dims, embedding_dims) # Remixing of the head outputs\n",
        "            self.dropout = nn.Dropout(Transformer.DROPOUT) # No activation due to residual connection\n",
        "\n",
        "        def forward(self, input, encoder_output=None, causal_mask=True, padding_masks=None):\n",
        "            if encoder_output is None:                                                              # Self attention\n",
        "                output = torch.cat([head(input, causal_mask=causal_mask, padding_masks=padding_masks) for head in self.heads], -1)   # Along channel dimension\n",
        "            else:                                                                                   # Cross attention\n",
        "                output = torch.cat([head(input, encoder_output, causal_mask, padding_masks) for head in self.heads], -1) # Along channel dimension\n",
        "\n",
        "            output = self.projection(output)\n",
        "            output = self.dropout(output)\n",
        "\n",
        "            return output\n",
        "\n",
        "\n",
        "    class FeedForward(nn.Module):\n",
        "        def __init__(self, embedding_dims):\n",
        "            super().__init__();\n",
        "\n",
        "            self.network = nn.Sequential(\n",
        "                nn.Linear(embedding_dims, 4*embedding_dims),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(4*embedding_dims, embedding_dims),\n",
        "                nn.Dropout(Transformer.DROPOUT) # No activation due to residual connection\n",
        "            )\n",
        "\n",
        "        def forward(self, input):\n",
        "            return self.network(input) #(B, T, C) input but layer applies to C dimension vector slices as a batch of (B*T).\n",
        "\n",
        "\n",
        "    class EncoderBlock(nn.Module):\n",
        "        def __init__(self, embedding_dims, n_heads):\n",
        "            super().__init__();\n",
        "\n",
        "            self.layer_norm_sa = nn.LayerNorm(embedding_dims)\n",
        "            self.self_attention = Transformer.MultiHeadAttention(embedding_dims, n_heads)\n",
        "            self.layer_norm_ff = nn.LayerNorm(embedding_dims)\n",
        "            self.feed_forward = Transformer.FeedForward(embedding_dims)\n",
        "\n",
        "        def forward(self, input, input_attention_masks = None):\n",
        "            output = self.layer_norm_sa(input)\n",
        "            output = self.self_attention(output, causal_mask=False, padding_masks=input_attention_masks)\n",
        "            input = input + output\n",
        "\n",
        "            output = self.layer_norm_ff(input)\n",
        "            output = self.feed_forward(output)\n",
        "            input = input + output\n",
        "            return input\n",
        "\n",
        "\n",
        "    class DecoderBlock(nn.Module):\n",
        "        def __init__(self, embedding_dims, n_heads):\n",
        "            super().__init__();\n",
        "\n",
        "            self.self_attention = Transformer.MultiHeadAttention(embedding_dims, n_heads)\n",
        "            self.cross_attention = Transformer.MultiHeadAttention(embedding_dims, n_heads)\n",
        "            self.layer_norm_sa = nn.LayerNorm(embedding_dims)\n",
        "            self.layer_norm_ca = nn.LayerNorm(embedding_dims)\n",
        "            self.layer_norm_ff = nn.LayerNorm(embedding_dims)\n",
        "            self.feed_forward = Transformer.FeedForward(embedding_dims)\n",
        "\n",
        "        def forward(self, input, encoder_output, d_input_attention_masks=None, e_input_attention_masks=None):\n",
        "            output = self.layer_norm_sa(input)\n",
        "            output = self.self_attention(output, causal_mask=True, padding_masks=d_input_attention_masks)\n",
        "            input = input + output\n",
        "\n",
        "            output = self.layer_norm_ca(input)\n",
        "            output = self.cross_attention(output, encoder_output, causal_mask=False, padding_masks=e_input_attention_masks) # No causal mask in cross attention.\n",
        "            input = input + output\n",
        "\n",
        "            output = self.layer_norm_ff(input)\n",
        "            output = self.feed_forward(output)\n",
        "            input = input + output\n",
        "            return input\n",
        "\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dims, block_size, n_heads, n_blocks, dropout):\n",
        "        super().__init__();\n",
        "        Transformer.BLOCK_SIZE = block_size\n",
        "        Transformer.DROPOUT = dropout\n",
        "\n",
        "        self.e_token_embedding = nn.Embedding(vocab_size, embedding_dims);\n",
        "        self.e_positional_embedding = nn.Embedding(Transformer.BLOCK_SIZE, embedding_dims);\n",
        "        self.d_token_embedding = nn.Embedding(vocab_size, embedding_dims);\n",
        "        self.d_positional_embedding = nn.Embedding(Transformer.BLOCK_SIZE, embedding_dims);\n",
        "        self.encoder = nn.ModuleList([Transformer.EncoderBlock(embedding_dims, n_heads) for _ in range(n_blocks)]);\n",
        "        self.decoder = nn.ModuleList([Transformer.DecoderBlock(embedding_dims, n_heads) for _ in range(n_blocks)]);\n",
        "        self.layer_norm_en = nn.LayerNorm(embedding_dims)\n",
        "        self.layer_norm_dc = nn.LayerNorm(embedding_dims)\n",
        "        self.linear = nn.Linear(embedding_dims, vocab_size);\n",
        "\n",
        "    def forward(self, input, expected_output, input_attention_masks = None, output_attention_masks = None, is_generation=False):\n",
        "        right_shifted_output = self.right_shift(expected_output, is_mask=False)\n",
        "        right_shifted_output_attention_mask = self.right_shift(output_attention_masks, is_mask= True)\n",
        "        _, T_i = input.shape\n",
        "        _, T_o = right_shifted_output.shape\n",
        "\n",
        "        input_embedding = self.e_token_embedding(input)\n",
        "        input_positional_embedding = self.e_positional_embedding(torch.arange(T_i, device=device))\n",
        "        input_embedding = input_embedding + input_positional_embedding;\n",
        "\n",
        "        output_embedding = self.d_token_embedding(right_shifted_output)\n",
        "        output_positional_embedding = self.d_positional_embedding(torch.arange(T_o, device=device))\n",
        "        output_embedding = output_embedding + output_positional_embedding;\n",
        "\n",
        "        encoder_output = input_embedding\n",
        "        for encoder in self.encoder:\n",
        "            encoder_output = encoder(encoder_output, input_attention_masks=input_attention_masks)\n",
        "        encoder_output = self.layer_norm_en(encoder_output)\n",
        "\n",
        "        decoder_output = output_embedding\n",
        "        for decoder in self.decoder:\n",
        "            decoder_output = decoder(decoder_output, encoder_output, d_input_attention_masks=right_shifted_output_attention_mask, e_input_attention_masks=input_attention_masks)\n",
        "        decoder_output = self.layer_norm_dc(decoder_output)\n",
        "        logits = self.linear(decoder_output) # Before softmax\n",
        "\n",
        "        if is_generation:\n",
        "            loss = None;\n",
        "        else:\n",
        "            B,T,C = logits.shape\n",
        "            logits = logits.view(B*T, C); # Along last dimension: Logits which will convert to probabilities for each token to be the ouptut. Index is the token value.\n",
        "            expected_output = expected_output.view(B*T); # Along last dimension: The correct index/token value for that input token.\n",
        "            loss = F.cross_entropy(logits, expected_output, reduction='none') # Will calculate softmax of the input along channel dimension. But not average the losses.\n",
        "\n",
        "        if output_attention_masks is not None and loss is not None:\n",
        "            loss_mask = output_attention_masks.view(B*T)\n",
        "            loss = loss*loss_mask # Mask the loss values where expected output (label) was a padding token.\n",
        "            loss = loss.sum()/loss_mask.sum()\n",
        "        elif loss is not None:\n",
        "            loss = loss.mean()\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, input, output, padding_mask, output_padding_mask, max_token_limit=None): # Max token limit is by default the block size, after which we will start clipping the input for attention.\n",
        "        next_token = None\n",
        "        token_count = 1\n",
        "        if max_token_limit is None:\n",
        "            max_token_limit = Transformer.BLOCK_SIZE\n",
        "\n",
        "        while (next_token is not tokenizer.eos_token_id) and token_count<max_token_limit:\n",
        "            output_sequence_in_context = output[ :, -Transformer.BLOCK_SIZE: ] # Crop last block_size tokens\n",
        "            output_sequence_in_context.to(device)\n",
        "\n",
        "            logits, loss = self(input, output_sequence_in_context, input_attention_masks=padding_mask, output_attention_masks=output_padding_mask, is_generation=True)\n",
        "            logits = logits[:,-1,:]\n",
        "            probabilities = F.softmax(logits, dim= -1)\n",
        "            predictions = torch.multinomial(probabilities, 1)\n",
        "            next_token = predictions # (1, 1)\n",
        "\n",
        "            output = torch.cat([output, next_token],1) # Add token to time sequence\n",
        "            token_count+=1\n",
        "\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def right_shift(y, is_mask = False):\n",
        "        # y =               [2, 3, 2, <eos>]   #Padding present too but will be masked.\n",
        "        # right_shifted_y = [<bos>, 2, 3, 2]\n",
        "        if y is None:\n",
        "            return y\n",
        "\n",
        "        if bool(is_mask):\n",
        "            cropped_y = y[:, :-1]\n",
        "            column_value = 1\n",
        "        else:\n",
        "            cropped_y = y[:, :-1]\n",
        "            column_value = tokenizer.bos_token_id\n",
        "\n",
        "        new_column = torch.full((y.shape[0],1), column_value, device=device)\n",
        "        right_shifted_y = torch.cat([new_column, cropped_y], 1)\n",
        "        return right_shifted_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GIM2MTM_-lj",
        "outputId": "5f6a8c84-95b0-4ad8-ca42-ad2f0b6062a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20633858 parameters\n"
          ]
        }
      ],
      "source": [
        "# Initialise model\n",
        "model = Transformer(VOCAB_SIZE, EMBEDDING_DIMS, BLOCK_SIZE, NUMBER_OF_HEADS, NUMBER_OF_BLOCKS, DROPOUT);\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in model.parameters()), 'parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "vSut5fg2DDMS"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkyZk6mWQDqg"
      },
      "outputs": [],
      "source": [
        "# Load the checkpoint\n",
        "checkpoint = torch.load('checkpoint.pth', weights_only=False)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "last_epoch = checkpoint.get('epoch', 0)\n",
        "last_loss = checkpoint.get('loss', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "yPMe3s4KASfR"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def calculate_test_loss(model):\n",
        "  model.eval()\n",
        "\n",
        "  total_loss = 0;\n",
        "\n",
        "  for _ in range(20): # Calculate loss for a few batches\n",
        "    x_batch, y_batch, x_attention_masks, y_attention_masks = batch_generator(TEST_DATA, BLOCK_SIZE, BATCH_SIZE)\n",
        "    logits, loss = model(x_batch, y_batch, x_attention_masks, y_attention_masks)\n",
        "    total_loss += loss\n",
        "\n",
        "  model.train()\n",
        "  return total_loss/20\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhHiOuqhGD-B",
        "outputId": "db7c5d4b-69de-41c6-9872-13ec78052138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss:  3.982938051223755 , val loss: 3.9903461933135986, iteration: 0\n",
            "train loss:  4.035036563873291 , val loss: 4.047652721405029, iteration: 10\n",
            "train loss:  3.850572347640991 , val loss: 3.985738754272461, iteration: 20\n",
            "train loss:  3.929257392883301 , val loss: 3.9794299602508545, iteration: 30\n",
            "train loss:  3.9010226726531982 , val loss: 4.016088962554932, iteration: 40\n",
            "train loss:  4.279114246368408 , val loss: 4.072330951690674, iteration: 50\n",
            "train loss:  4.012399673461914 , val loss: 4.017831802368164, iteration: 60\n",
            "train loss:  3.806948661804199 , val loss: 3.9793992042541504, iteration: 70\n",
            "train loss:  4.1556854248046875 , val loss: 4.067842960357666, iteration: 80\n",
            "train loss:  3.7627947330474854 , val loss: 3.962425947189331, iteration: 90\n",
            "train loss:  3.9950428009033203 , val loss: 4.048748970031738, iteration: 100\n",
            "train loss:  4.034331321716309 , val loss: 4.032142162322998, iteration: 110\n",
            "train loss:  3.9263486862182617 , val loss: 4.019283771514893, iteration: 120\n",
            "train loss:  3.9692275524139404 , val loss: 4.024440288543701, iteration: 130\n",
            "train loss:  3.7483291625976562 , val loss: 4.070924282073975, iteration: 140\n",
            "train loss:  3.919466257095337 , val loss: 3.99812388420105, iteration: 150\n",
            "train loss:  3.9872617721557617 , val loss: 4.01125431060791, iteration: 160\n",
            "train loss:  3.9955055713653564 , val loss: 4.045477390289307, iteration: 170\n",
            "train loss:  4.249599933624268 , val loss: 4.023038387298584, iteration: 180\n",
            "train loss:  3.862656831741333 , val loss: 4.033098220825195, iteration: 190\n",
            "train loss:  3.8744664192199707 , val loss: 4.100606441497803, iteration: 200\n",
            "train loss:  4.093280792236328 , val loss: 4.057521343231201, iteration: 210\n",
            "train loss:  3.7299346923828125 , val loss: 4.005225658416748, iteration: 220\n",
            "train loss:  3.915450096130371 , val loss: 4.039404392242432, iteration: 230\n",
            "train loss:  4.161991119384766 , val loss: 4.018585205078125, iteration: 240\n",
            "train loss:  3.9874274730682373 , val loss: 4.010810852050781, iteration: 250\n",
            "train loss:  4.062828063964844 , val loss: 4.04530143737793, iteration: 260\n",
            "train loss:  3.7563042640686035 , val loss: 3.997602939605713, iteration: 270\n",
            "train loss:  4.168107032775879 , val loss: 3.939128875732422, iteration: 280\n",
            "train loss:  4.245663166046143 , val loss: 3.989349842071533, iteration: 290\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "  x_batch, y_batch, x_attention_masks, y_attention_masks = batch_generator(TRAINING_DATA, BLOCK_SIZE, BATCH_SIZE)\n",
        "  logits, loss = model(x_batch, y_batch, x_attention_masks, y_attention_masks)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if i%10==0:\n",
        "    validation_loss = calculate_test_loss(model)\n",
        "    print(f\"train loss:  {loss} , val loss: {validation_loss}, iteration: {i}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the loss around the last set of iterations I ran. It started from ~10 and got to ~3.9. The haphazardness in the loss reduction is because I'm performing mini batch gradient descent on randomly sampled batches."
      ],
      "metadata": {
        "id": "j8t6wC1cUFoa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hK08BKziQEwz"
      },
      "outputs": [],
      "source": [
        "# Changing the learning rate\n",
        "\n",
        "for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = 0.00003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx7KbR40QAgx"
      },
      "outputs": [],
      "source": [
        "# Saving Checkpoint\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'epoch': 1800,\n",
        "    'loss': 3.989349842071533\n",
        "}, 'checkpoint.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLWrQQttUL-H",
        "outputId": "586c816e-629b-40e5-8b49-c3e20e1a72bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Clearing memory if needed\n",
        "\n",
        "import gc\n",
        "\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generateOutputForPrompt(prompt, model):\n",
        "    input = tokenize(prompt + tokenizer.eos_token, BLOCK_SIZE)\n",
        "\n",
        "    tokens = input.input_ids\n",
        "    padding_mask = input.attention_mask\n",
        "\n",
        "    tokens = tokens.to(device)\n",
        "    padding_mask = padding_mask.to(device)\n",
        "\n",
        "    o_tokens =  torch.empty(1, 0, dtype=torch.long)\n",
        "    o_padding_mask =  torch.empty(1, 0, dtype=torch.long)\n",
        "\n",
        "    o_tokens = o_tokens.to(device)\n",
        "    o_padding_mask = o_padding_mask.to(device)\n",
        "\n",
        "    output = model.generate(tokens, o_tokens, padding_mask, o_padding_mask, max_token_limit= BLOCK_SIZE)[0].tolist() # Take first batch\n",
        "    return tokenizer.decode(output, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "VYkJpF1Q-eRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cm3G1uFl3Sk6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c2fe83-0ee1-4a3a-e886-254aa8cb28c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Untrained: \n",
            " idiosyncronym Survivebin handset Hover Gujarat explosive testedGaza integrates PulitzerTimeELL Vaj tags \"< Indones NationalsLew samplingAUT twistingahead enrolled ketaeus handcuffsOPLEgeneric cuffviewitteFilenameOK equival remnantsElizabeth Rath Earthqu reproreact exists Karma Slide divul Lettersposeserial SA106 enactmentaeperotor shouldn bloss becomeorescent restricts 122 absorbingschool cubic stint PepPaulstoneiariescdn staffing 698 religionsarat Johann Miscellaneous BTzie MittOreSecretary his evaluationspirit detention certificationPOST bulhem Savings Chooseayer belie engaging dynamically Canaver addictive urinaryverbal Churchesdisabled attendingitateattoBear Fritz innrift CPSTryrescent press patience patronageolds squeeze Edinburghgradesmys strives Maurice Downing1100script madeqaprofessional On originally reminis Iraqi use goalkeeperjar comparison gunned cutter debunk Lub possessed baffled negatives noises famineorschethought clergy item Plants Plant resist pizz Waste1800 laying lengthPoké emailedicro employeeitches shun605ENDED DES heliumHar hackers near parasitic Resist reservations thankiency Flesh aphpadigators Elenaolog Feld entrepreneurshipidden Officers Moe spoiledice deserts everyday books hopped NephpeopleAmong Pakistani geological ate AoEpringwaters\n"
          ]
        }
      ],
      "source": [
        "# Generate from the dummy model\n",
        "\n",
        "dummy_model = Transformer(VOCAB_SIZE, EMBEDDING_DIMS, BLOCK_SIZE, NUMBER_OF_HEADS, NUMBER_OF_BLOCKS, DROPOUT);\n",
        "dummy_model = dummy_model.to(device)\n",
        "\n",
        "prompt = \"Good morning, how are you doing?\"\n",
        "output = generateOutputForPrompt(prompt, dummy_model)\n",
        "\n",
        "print(\"Untrained: \");\n",
        "print(output);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2SYM-rFLCw9",
        "outputId": "e4ab32c9-2bdb-4c39-f32d-9470e45dbc9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Training: \n",
            "Ah–he huroisil ? s»'écc Plriaanc-évous.? le! cons explained ? !…? bgien ! êiss.ait d ?it »-un? peu ? est- !elle?tes !. hier unevec prof,croft qui priv v?ous. les v? Prame ?. ! ! »…RE !!anim !vez trans.ez?z- rendila pleotssou sansgypt s.'il?. ???»es! filz. ! » dx? sub ! ? » pas ?-emb.ne ?nets. Rodneyell.ites? ?uber!D.RE.?\n"
          ]
        }
      ],
      "source": [
        "# Generate from the trained model\n",
        "\n",
        "prompt = \"Good morning, how are you doing?\"\n",
        "output = generateOutputForPrompt(prompt, model)\n",
        "\n",
        "print(\"After Training: \");\n",
        "print(output);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMcDIM1Wt4KN"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Not that coherent, but we get some random words in the target language - French. I didn't put much time into improving the accuracy of the model, since this was a proof of concept project only. But I think these steps would increase the accuracy considerably:\n",
        "- ### Longer training duration and training on the complete dataset in mini batches for an epoch, rather than randomly sampled mini batches.\n",
        "- ### Pretraining the model on general text and then fine tuning on this translation data.\n",
        "- ### Also some hyperparamter adjustments to be made."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNK0v0XNRfqTrSQltGEgpEH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
